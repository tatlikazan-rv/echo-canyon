{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19721,"status":"ok","timestamp":1646916087805,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"},"user_tz":-60},"id":"esPx5NX7saNe","outputId":"5787ba36-0b22-4b7e-c7bc-04414b8eecc4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"esPx5NX7saNe"},{"cell_type":"markdown","metadata":{"id":"122908d6"},"source":["# General Imports"],"id":"122908d6"},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"PnhP1xG43GIe","executionInfo":{"status":"ok","timestamp":1646916126711,"user_tz":-60,"elapsed":38919,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}},"outputId":"13b300a2-3d18-499f-dbb1-0207053d4a32"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting GPUtil\n","  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n","Building wheels for collected packages: GPUtil\n","  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for GPUtil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=950588da641b98eca955157ea90c9a30900ddba2a1642dd9a1aee2576726cc33\n","  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n","Successfully built GPUtil\n","Installing collected packages: GPUtil\n","Successfully installed GPUtil-1.4.0\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 312 kB 9.7 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 212 kB 88.0 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 134 kB 97.1 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 80.7 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67 kB 6.1 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 127 kB 93.4 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 144 kB 77.6 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 94 kB 3.7 MB/s \n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 271 kB 68.4 MB/s \n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[?25hCollecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.8 MB 8.4 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.5 MB 64.4 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Collecting sacremoses\n","  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 895 kB 78.8 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 56.6 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed pyyaml-6.0 sacremoses-0.0.47 tokenizers-0.11.6 transformers-4.17.0\n","Collecting tf-models-official\n","  Downloading tf_models_official-2.8.0-py2.py3-none-any.whl (2.2 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.2 MB 8.1 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow~=2.8.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (2.8.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (3.2.2)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.5.12)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.15.0)\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 43 kB 2.6 MB/s \n","\u001b[?25hRequirement already satisfied: pandas>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.3.5)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (2.0.4)\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.0.1)\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 99 kB 11.9 MB/s \n","\u001b[?25hCollecting pyyaml<6.0,>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 636 kB 69.2 MB/s \n","\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.5.0)\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.2 MB 77.7 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (5.4.8)\n","Collecting tensorflow-addons\n","  Downloading tensorflow_addons-0.16.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1 MB 54.9 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.12.0)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.12.10)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 90 kB 13.0 MB/s \n","\u001b[?25hCollecting tensorflow-text~=2.8.0\n","  Downloading tensorflow_text-2.8.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.9 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.9 MB 66.9 MB/s \n","\u001b[?25hRequirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (0.29.28)\n","Collecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.7.1-py2.py3-none-any.whl (234 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 234 kB 80.5 MB/s \n","\u001b[?25hCollecting tf-slim>=1.1.0\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 352 kB 81.0 MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.4.1)\n","Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (1.21.5)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (4.1.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from tf-models-official) (7.1.2)\n","Collecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 47.8 MB 1.1 MB/s \n","\u001b[?25hRequirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.17.4)\n","Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (3.0.1)\n","Requirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.26.3)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.0.4)\n","Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official) (1.35.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (3.17.3)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (21.3)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2.23.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (57.4.0)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (1.55.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2018.9)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (0.2.8)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (4.2.4)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (4.63.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (6.1.1)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (1.25.11)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2021.10.8)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.8.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (3.0.7)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official) (3.0.4)\n","Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (2.8.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.1.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.44.0)\n","Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (13.0.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (0.24.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (3.1.0)\n","Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.0.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.1.2)\n","Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (2.0)\n","Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (2.8.0)\n","Collecting tf-estimator-nightly==2.8.0.dev2021122109\n","  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 462 kB 93.1 MB/s \n","\u001b[?25hRequirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (0.5.3)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (3.3.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (3.10.0.2)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (0.2.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.13.3)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.8.0->tf-models-official) (1.6.3)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->tf-models-official) (0.37.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.8.0->tf-models-official) (1.5.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (3.3.6)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (0.4.6)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (1.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (1.0.1)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (0.6.1)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (4.11.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (3.7.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->tf-models-official) (3.2.0)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.6)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->tf-models-official) (1.3.2)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official) (1.3)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting portalocker\n","  Downloading portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official) (0.8.9)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official) (2019.12.20)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official) (1.0.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (1.1.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official) (3.1.0)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official) (2.7.1)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (2.3)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (5.4.0)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (21.4.0)\n","Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.3.4)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (0.16.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official) (1.7.0)\n","Building wheels for collected packages: py-cpuinfo, seqeval\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=298707269488c47c201e88a5e939eeec22e0f1cd1450534b879c387297f4706a\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=c977e4a354a46dcc7841a16aa5be13287a323cd2d2be81fcd135026574634361\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built py-cpuinfo seqeval\n","Installing collected packages: tf-estimator-nightly, portalocker, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, opencv-python-headless, tf-models-official\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 6.0\n","    Uninstalling PyYAML-6.0:\n","      Successfully uninstalled PyYAML-6.0\n","Successfully installed colorama-0.4.4 opencv-python-headless-4.5.5.64 portalocker-2.4.0 py-cpuinfo-8.0.0 pyyaml-5.4.1 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.16.1 tensorflow-model-optimization-0.7.1 tensorflow-text-2.8.1 tf-estimator-nightly-2.8.0.dev2021122109 tf-models-official-2.8.0 tf-slim-1.1.0\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (5.4.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.5)\n"]},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\nIf you have ongoing issues with the transformers library, Also consider installing from source: \\ngit clone https://github.com/huggingface/transformers.git \\ncd transformers (in Dropbox/C/25_Studium_Master/TUM_RCI/2021_WS/NLP/3-Exercises-Workspace/transformers)\\npip install -e\\nAlso update git\\n'"]},"metadata":{},"execution_count":2}],"source":["!pip install GPUtil                   # to check GPU usage\n","!pip install -q bs4                   # to clean the lyrics\n","!pip install -q datasets\n","!pip install transformers             # for training\n","# Update Transformers from the source if you get errors:\n","# !pip install git + https://github.com/huggingface/transformers\n","!pip install tf-models-official       # for optimization\n","!pip install pyyaml h5py              # to save the models\n","\n","\"\"\"\n","If you have ongoing issues with the transformers library, Also consider installing from source: \n","git clone https://github.com/huggingface/transformers.git \n","cd transformers (in Dropbox/C/25_Studium_Master/TUM_RCI/2021_WS/NLP/3-Exercises-Workspace/transformers)\n","pip install -e\n","Also update git\n","\"\"\""],"id":"PnhP1xG43GIe"},{"cell_type":"code","execution_count":3,"metadata":{"id":"d295d957","executionInfo":{"status":"ok","timestamp":1646916137952,"user_tz":-60,"elapsed":11259,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras\n","from transformers import AutoConfig, AutoTokenizer, TFAutoModelForCausalLM, default_data_collator, pipeline \n","# DefaultDataCollator: for the error https://github.com/huggingface/transformers/pull/5015\n","from official.nlp import optimization\n","from datasets import Dataset      # https://huggingface.co/docs/datasets/\n","from bs4 import BeautifulSoup     # easy webscraping\n","import requests                   # for sending http requests\n","import re                         # regular expressions, excellent for string searching/replacing, \n","# extremely powerful for manual NLP, check out the documentation at https://docs.python.org/3/library/re.html\n","import os                         # accessing file paths\n","# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" to deactive GPU\n","import json\n","import random\n","from collections import Counter\n","import math\n","import GPUtil\n","from numba import cuda \n","\n","model_name = \"gpt2\"               # selected pretrained language model from https://huggingface.co/models\n","\n","# \"gtp3\" is huge, needed several GPUs for traning, didnt fit in to Colab Pro Machine. \n","# I tried distilgpt2 on my machine. But even then I ran in to problems with OOM \n","# errors often before switching to Google Colab Pro (10euro/month) for efficiency\n","# as I only have a GeForce GTX M 860 with 4 GB memory. I didn't try distilgpt2\n","# here again as I direct could use gpt2."],"id":"d295d957"},{"cell_type":"code","execution_count":4,"metadata":{"id":"X48IcEdVc3oD","executionInfo":{"status":"ok","timestamp":1646916137954,"user_tz":-60,"elapsed":23,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"41810f0e-247c-4823-da59-996dbfb2fb89"},"outputs":[{"output_type":"stream","name":"stdout","text":["| ID | GPU | MEM |\n","------------------\n","|  0 |  0% |  0% |\n"]}],"source":["from tensorflow import keras\n","GPUtil.showUtilization()"],"id":"X48IcEdVc3oD"},{"cell_type":"markdown","metadata":{"id":"v1QcBPYssvUe"},"source":["# Generator <a class=\"anchor\" id=\"Generator\"></a>"],"id":"v1QcBPYssvUe"},{"cell_type":"code","execution_count":43,"metadata":{"id":"440f5c75","executionInfo":{"status":"ok","timestamp":1646924854770,"user_tz":-60,"elapsed":749,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["# FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","# CHANGES: Changed the directories to save genres separately \n","\n","# loading saved lyrics files\n","\n","# Utilized commenting to train 6 different models for every genre instead of \n","# having 6 notebooks. As I save them after training reloading and generating lyrics \n","# in all genres is no issue. \n","\n","#with open(\"/content/drive/MyDrive/EchoCanyon/lyrics/blues_lyrics.json\", \"r\", encoding = \"utf8\") as f:\n","#with open(\"/content/drive/MyDrive/EchoCanyon/lyrics/country_lyrics.json\", \"r\", encoding = \"utf8\") as f:\n","#with open(\"/content/drive/MyDrive/EchoCanyon/lyrics/jazz_lyrics.json\", \"r\", encoding = \"utf8\") as f:\n","with open(\"/content/drive/MyDrive/EchoCanyon/lyrics/metal_lyrics.json\", \"r\", encoding = \"utf8\") as f:\n","#with open(\"/content/drive/MyDrive/EchoCanyon/lyrics/pop_lyrics.json\", \"r\", encoding = \"utf8\") as f:\n","#with open(\"/content/drive/MyDrive/EchoCanyon/lyrics/rock_lyrics.json\", \"r\", encoding = \"utf8\") as f:\n","\n","    lyrics_dict = {}\n","    lyrics_dict = json.load(f)"],"id":"440f5c75"},{"cell_type":"code","execution_count":44,"metadata":{"id":"911dfedb","executionInfo":{"status":"ok","timestamp":1646924854771,"user_tz":-60,"elapsed":8,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["# FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","# CHANGES: None\n","\n","# reformatting lyrics\n","\n","lyrics = {\"text\":[], \"artist\":[]}\n","for artist, titles in lyrics_dict.items():\n","    \n","    for title, text in titles.items():\n","        \n","        lyrics[\"artist\"].append(artist)\n","        lyrics[\"text\"].append(text)"],"id":"911dfedb"},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"49334690","executionInfo":{"status":"ok","timestamp":1646924857858,"user_tz":-60,"elapsed":2776,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}},"outputId":"12d8eb5e-d94b-4f54-b6cc-bd8f951f8c07"},"outputs":[{"output_type":"stream","name":"stdout","text":["['[', ' 1', ']', '\\n', 'Open', ' door', ',', ' so', ' I', ' walk', ' inside', '\\n', 'Close', ' my', ' eyes', ',', ' find', ' my', ' place', ' to', ' hide', '\\n', 'And', ' I', ' shake', ' as', ' I', ' take', ' it', ' in', '\\n', 'Let', ' the', ' show', ' begin', '\\n', 'Open', ' my', ' eyes', ' just', ' to', ' have', ' them', ' close', ' again', '\\n', 'Well', ' on', ' my', ' way', ',', ' but', ' on', ' my', ' way', ' to', ' where', ' I']\n"]}],"source":["# FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","# CHANGES: None\n","\n","# AutoTokenizer will find and load the right tokenizer for all common models in the huggingface library\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","i = random.randint(0, len(lyrics[\"text\"]))\n","example_text = lyrics[\"text\"][i][0:200]\n","example_text_tokenized = tokenizer(example_text)\n","print([tokenizer.decode(token) for token in example_text_tokenized[\"input_ids\"]])"],"id":"49334690"},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcfb5967","executionInfo":{"status":"ok","timestamp":1646924857859,"user_tz":-60,"elapsed":27,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}},"outputId":"a0ec05ea-75f3-4e4c-ac01-53225b42c2d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['text', 'artist'],\n","    num_rows: 725\n","})\n"]}],"source":["# FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","# CHANGES: None\n","\n","# transforming lyrics into dataset format\n","\n","dataset = Dataset.from_dict(lyrics)\n","print(dataset)"],"id":"fcfb5967"},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":173,"referenced_widgets":["f89013d7ea76426f9082eb56b448a109","26863a415ad54d348db61a3156bda070","fb63372d3d43472dace6bbf625a69620","d8a51ddadcb84bd98e1f4f4b1d8e92b9","7e312471bad64ecc8f8164d7b2ed455f","7746bc0d825e45608dbea1cb69c8bb53","778b8e3f32534c3f804af7be9923c78c","0f32cadc2fac47d9b2ab72592c726afa","88283314cd3f47e997defe1b4e8f2da8","64aa5a41b1074e399d1c9e533b9b01c2","fe346866658e4823aa271a47b82ae19f"]},"id":"c6ae3784","executionInfo":{"status":"ok","timestamp":1646924859900,"user_tz":-60,"elapsed":2063,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}},"outputId":"17074647-302e-484b-9e07-0d74ba9a49c9"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f89013d7ea76426f9082eb56b448a109","version_minor":0,"version_major":2},"text/plain":["0ex [00:00, ?ex/s]"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (1025 > 1024). Running this sequence through the model will result in indexing errors\n"]},{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['artist', 'tokens'],\n","    num_rows: 725\n","})\n","['Free', ' fall', ' through', ' our', ' midnight', '\\n', 'This', ' ep', 'il', 'ogue', ' of', ' our', ' own', ' f', 'able', '\\n', 'He', 'ed', 'less', ' in']\n"]}],"source":["# FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","# CHANGES: None\n","\n","# tokenizing before chunking, to ensure equal lengths\n","\n","def pretokenization(text, tokenizer):\n","    tokens = tokenizer(text, truncation = False, add_special_tokens = False, return_attention_mask = False)\n","    return {\"tokens\":[tokenizer.decode(token) for token in tokens[\"input_ids\"]]}\n","\n","tokenized_dataset = dataset.map(lambda x: pretokenization(x[\"text\"],tokenizer), remove_columns = [\"text\"])\n","print(tokenized_dataset)\n","i = random.randint(0, len(dataset[\"text\"]))\n","print(tokenized_dataset[\"tokens\"][i][0:20])"],"id":"c6ae3784"},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":153,"referenced_widgets":["9b529b573071433bac9d2a6382555eef","221ddad183584a37a0cb6f2ba660f32f","fffc839e3a494667b86cb003ea29d3d4","ef25eeccd69942d880da58f5eb7f61f4","2ea301bf4d1042b8a8a9a7835ae38e48","bb240db5ee654bbcb4d0cd411384085b","85e5d9f99cb94ec382a8cacdd959b95d","2ab6c024ca814d4b90cb61c29742bb21","1f8951d1840e47e6b01f275286e01356","9fde0dce55b14d94850898cf6a1954a9","2aa9e26798704940b789c3975ec432f9"]},"id":"3886afe6","executionInfo":{"status":"ok","timestamp":1646924860728,"user_tz":-60,"elapsed":851,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}},"outputId":"51646c03-1809-4fbe-db64-9e8f26e6faa8"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9b529b573071433bac9d2a6382555eef","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["25\n","25\n","Dataset({\n","    features: ['artist', 'tokens'],\n","    num_rows: 8519\n","})\n"]}],"source":["# FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","# CHANGES: None\n","\n","# chunking the lyrics into parts of equal length\n","# greater chunks allow longer-range dependencies but also increase computation \n","chunk_size = 25  # increases computation quadraticly, basically\n","# depens on how many close words to consider during training over the current word \n","#\n","\n","def chunking(examples, chunk_size):\n","    chunks = []\n","    artists = []\n","    for tokens, artist in zip(examples[\"tokens\"], examples[\"artist\"]):\n","\n","        for i in range(0, len(tokens)-chunk_size, chunk_size):\n","            \n","            chunks.append(tokens[i:i+chunk_size])\n","            artists.append(artist)\n","    \n","    return {'tokens': chunks, \"artist\": artists}\n","\n","chunked_dataset = tokenized_dataset.map(lambda x: chunking(x, chunk_size), batched = True, \n","                                        remove_columns = tokenized_dataset.column_names)\n","\n","# check if all chunks are of equal length\n","print(max(len(ids) for ids in chunked_dataset[\"tokens\"]))\n","print(min(len(ids) for ids in chunked_dataset[\"tokens\"]))\n","\n","print(chunked_dataset)"],"id":"3886afe6"},{"cell_type":"code","execution_count":49,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":136,"referenced_widgets":["3209cbcf94a643e0a82d00cfcaaa1817","3d5c99c164504ed4beb8428653197eb4","f1a4c4c086c8410fb319107452e3dac5","4715902f29494193935c4d838feac8f4","02bea20926b3445cb988ed2c6b8063b6","0662bf0dc1d94092b231412ee8bb05af","c9aced323b8c4a09b5da0e7c99fae967","e6c053e1a1d143118731999306f7bce3","09506516eedd4d5e9d5f5c5588a8b7c1","31b93b65cd9a45718a6441c4f0b07d46","4d286f58c0d9451da57b5d8f0b879d2f"]},"id":"c6ddcdfc","executionInfo":{"status":"ok","timestamp":1646924860730,"user_tz":-60,"elapsed":20,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}},"outputId":"029f6637-f220-4545-a8ca-8a1af3cf2c1c"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3209cbcf94a643e0a82d00cfcaaa1817","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/1 [00:00<?, ?ba/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['artist', 'tokens'],\n","    num_rows: 5055\n","})\n","[('megadeth', 1011), ('metallica', 1011), ('dio', 1011), ('tool', 1011), ('black_sabbath', 1011)]\n"]}],"source":["# FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","# CHANGES: None\n","\n","# stratifying by artist\n","\n","n = Counter(chunked_dataset[\"artist\"]).most_common()[-1][1]  # from library->Collections\n","\n","def stratifying(examples, n):  # to have same amount of lines from both artists\n","    \n","    chunks = []\n","    artists = []\n","    \n","    for artist in set(examples[\"artist\"]):\n","        \n","        artist_chunks = [chunk for a, chunk in zip(examples[\"artist\"], examples[\"tokens\"]) if a == artist]\n","        artist_chunks = random.sample(artist_chunks, n)\n","        \n","        for chunk in artist_chunks:\n","            \n","            chunks.append(chunk)\n","            artists.append(artist)\n","        \n","        \n","    return {'tokens': chunks, \"artist\": artists}\n","    \n","stratified_dataset = chunked_dataset.map(lambda x: stratifying(x, n), batched = True, batch_size = None,\n","                                        remove_columns = tokenized_dataset.column_names)\n","\n","print(stratified_dataset)\n","print(Counter(stratified_dataset[\"artist\"]).most_common())"],"id":"c6ddcdfc"},{"cell_type":"code","execution_count":50,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["b362d745ab83403b9e51ebdca3a36fcb","9ee49089b35f4513965a422cc799c7fb","65052c2bfea0441eb8b255a3a5daa720","73ac942d8f624b7888dfe5013e2606ce","d3615fcb16eb42b5ad3133c419428c44","b7359751809e467e90a44e42b61b62e1","b0ac0d219ff245c887a7b43ab6d64734","35df29c9c08147f5858f9f3f2014a5ca","14a948cd79514f2c90f4ab029893502d","8fee981946e64056bcae6e5b8d33e367","57278ee7e13f4bb29ff8a7c80a1835f3"]},"id":"aa811315","executionInfo":{"status":"ok","timestamp":1646924867355,"user_tz":-60,"elapsed":6280,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}},"outputId":"060068ac-6f21-49a9-82fd-c74d3b5b9b2b"},"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b362d745ab83403b9e51ebdca3a36fcb","version_minor":0,"version_major":2},"text/plain":["0ex [00:00, ?ex/s]"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Dataset({\n","    features: ['artist', 'tokens', 'input_ids', 'labels', 'attention_mask'],\n","    num_rows: 5055\n","})\n"]}],"source":["# FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","# CHANGES: None\n","\n","# running tokenization again, to retrieve input_ids, labels and the attention_masks\n","\n","def tokenization(tokens):\n","    tokenized = tokenizer(tokens)\n","    return  {\"input_ids\": tf.squeeze(tokenized[\"input_ids\"]),\n","             # duplicating the inputs for our labels\n","             # \"the model of the ðŸ¤— Transformers library apply the shifting to the right, so we don't need to do it manually\"\n","             \"labels\": tf.squeeze(tokenized[\"input_ids\"]), \n","             \"attention_mask\": tf.squeeze(tokenized[\"attention_mask\"])}\n","\n","final_dataset = stratified_dataset.map(lambda x:tokenization(x[\"tokens\"]))\n","print(final_dataset)"],"id":"aa811315"},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b809754f","executionInfo":{"status":"ok","timestamp":1646924867356,"user_tz":-60,"elapsed":24,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}},"outputId":"1f58e9f2-36b1-4375-93b1-2875d2a6f2c9"},"outputs":[{"output_type":"stream","name":"stdout","text":["<TakeDataset element_spec={'labels': TensorSpec(shape=(2, None), dtype=tf.int64, name=None), 'input_ids': TensorSpec(shape=(2, None), dtype=tf.int64, name=None), 'attention_mask': TensorSpec(shape=(2, None), dtype=tf.int64, name=None)}>\n"]}],"source":["# FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","# CHANGES: None\n","\n","# shuffling, batching, splitting  # needed when using tf and it needs to be transfored to a Tensorflow Dataset\n","from transformers import DefaultDataCollator\n","\n","batch_size = 2\n","n_batches = round(final_dataset.num_rows/batch_size)\n","n_eval_batches = round(0.1*n_batches)\n","n_train_batches = n_batches - n_eval_batches\n","\n","\n","# transforming to a tensorflow dataset\n","data_collator = DefaultDataCollator(return_tensors= \"tf\")\n","\n","tf_dataset = final_dataset.to_tf_dataset(columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n","                                                                     shuffle = True, \n","                                                                     batch_size = batch_size,\n","                                                                     collate_fn = data_collator)\n","\n","# !!!!! Important: setting the seed does not prevent different shuffling at each epoch, \n","# !!!!! set reshuffle_each_iteration=False if used\n","\n","\n","tf_train_dataset = tf_dataset.take(n_train_batches)\n","tf_eval_dataset = tf_dataset.skip(n_train_batches).take(n_eval_batches)\n","\n","print(tf_train_dataset)"],"id":"b809754f"},{"cell_type":"code","execution_count":52,"metadata":{"id":"b7fe9826","executionInfo":{"status":"ok","timestamp":1646924867710,"user_tz":-60,"elapsed":366,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["# FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","# CHANGES: None\n","\n","# inspecting the configuration of the pretrained model\n","config = AutoConfig.from_pretrained(model_name)\n","\n","# for more elaboration of all the configuration details check here:\n","# https://huggingface.co/docs/transformers/model_doc/gpt2#transformers.GPT2Config\n","# print(config)\n","\n","# \"n_ctx\": 1024, sequence dim\n","# \"n_embd\": 768, embedding dim\n","# \"n_head\": 12, num of attetion heads"],"id":"b7fe9826"},{"cell_type":"code","execution_count":53,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92d11266","executionInfo":{"status":"ok","timestamp":1646924869016,"user_tz":-60,"elapsed":1313,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}},"outputId":"0d8bc7f8-0088-4d44-ae13-ee6662a9453e"},"outputs":[{"output_type":"stream","name":"stderr","text":["All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n","\n","All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"]}],"source":["# FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","# CHANGES: None\n","\n","# loading the model including its causal language modeling head\n","\n","model = TFAutoModelForCausalLM.from_pretrained(model_name)"],"id":"92d11266"},{"cell_type":"code","execution_count":54,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4db0d73f","executionInfo":{"status":"ok","timestamp":1646924883035,"user_tz":-60,"elapsed":14034,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}},"outputId":"1f0bcc52-af06-4755-d3fb-7d6d6ad84bd2"},"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"]},{"output_type":"stream","name":"stdout","text":["Peace sells but who is buying it?\n","\n","It's hard to define the difference between \"bespoke\" and \"snowflake\" or between anything that really tastes like Apple. That is, if you are trying to decide whether to buy\n"]}],"source":["# FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","# CHANGES: None\n","\n","# testing the pretrained model as is\n","\n","generator = pipeline('text-generation',model=model, tokenizer=tokenizer) \n","# for more detailed tuning you have to implement differently\n","# for that the tokenization works\n","# for different amount of randomness etc.\n","\n","\n","prompt = \"Peace sells but who is buying\"\n","\n","print(generator(prompt)[0][\"generated_text\"])\n","# so you can see it wasnt trained on lyrics"],"id":"4db0d73f"},{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6a44875d","executionInfo":{"status":"ok","timestamp":1646924883036,"user_tz":-60,"elapsed":14,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}},"outputId":"a4422957-344d-4fa2-a6cc-00a11213f26c"},"outputs":[{"output_type":"stream","name":"stderr","text":["No loss specified in compile() - the model's internal loss computation will be used as the loss. Don't panic - this is a common way to train TensorFlow models in Transformers! Please ensure your labels are passed as keys in the input dict so that they are accessible to the model during the forward pass. To disable this behaviour, please pass a loss argument, or explicitly pass loss=None if you do not want your model to compute a loss.\n"]}],"source":["# FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","# CHANGES: Hyperparameter Tuning see next section\n","\n","# initializing the optimizer and defining our learning rate schedule\n","\n","epochs = 50\n","num_train_steps = epochs * n_train_batches\n","warmup_ratio = 0.1\n","num_warmup_steps = int(warmup_ratio*num_train_steps)\n","\n","init_lr = 1e-3\n","\n","optimizer = optimization.create_optimizer(init_lr=init_lr,\n","                                          num_train_steps=num_train_steps,\n","                                          num_warmup_steps=num_warmup_steps,\n","                                          optimizer_type='adamw')\n","\n","# compiling the model\n","model.compile(optimizer=optimizer)"],"id":"6a44875d"},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"61487b7a","outputId":"d34a1f90-479c-4a83-c3f4-b237f85adb86","executionInfo":{"status":"ok","timestamp":1646931348091,"user_tz":-60,"elapsed":6465063,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","2275/2275 [==============================] - 150s 59ms/step - loss: 3.9930 - val_loss: 3.2925\n","Epoch 2/50\n","2275/2275 [==============================] - 133s 58ms/step - loss: 3.5264 - val_loss: 2.7783\n","Epoch 3/50\n","2275/2275 [==============================] - 133s 58ms/step - loss: 3.1613 - val_loss: 2.4070\n","Epoch 4/50\n","2275/2275 [==============================] - 132s 58ms/step - loss: 2.8554 - val_loss: 2.0490\n","Epoch 5/50\n","2275/2275 [==============================] - 128s 56ms/step - loss: 2.6186 - val_loss: 1.8219\n","Epoch 6/50\n","2275/2275 [==============================] - 126s 56ms/step - loss: 2.2156 - val_loss: 1.3248\n","Epoch 7/50\n","2275/2275 [==============================] - 127s 56ms/step - loss: 1.7706 - val_loss: 1.0176\n","Epoch 8/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 1.4344 - val_loss: 0.8199\n","Epoch 9/50\n","2275/2275 [==============================] - 126s 55ms/step - loss: 1.1895 - val_loss: 0.6531\n","Epoch 10/50\n","2275/2275 [==============================] - 126s 55ms/step - loss: 0.9987 - val_loss: 0.5727\n","Epoch 11/50\n","2275/2275 [==============================] - 127s 56ms/step - loss: 0.8681 - val_loss: 0.4888\n","Epoch 12/50\n","2275/2275 [==============================] - 127s 56ms/step - loss: 0.7598 - val_loss: 0.4827\n","Epoch 13/50\n","2275/2275 [==============================] - 129s 57ms/step - loss: 0.6881 - val_loss: 0.4253\n","Epoch 14/50\n","2275/2275 [==============================] - 130s 57ms/step - loss: 0.6251 - val_loss: 0.3811\n","Epoch 15/50\n","2275/2275 [==============================] - 129s 57ms/step - loss: 0.5676 - val_loss: 0.3533\n","Epoch 16/50\n","2275/2275 [==============================] - 128s 56ms/step - loss: 0.5224 - val_loss: 0.3111\n","Epoch 17/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 0.4812 - val_loss: 0.3079\n","Epoch 18/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 0.4560 - val_loss: 0.2860\n","Epoch 19/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 0.4281 - val_loss: 0.2664\n","Epoch 20/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 0.3958 - val_loss: 0.2584\n","Epoch 21/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 0.3734 - val_loss: 0.2560\n","Epoch 22/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 0.3551 - val_loss: 0.2453\n","Epoch 23/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 0.3368 - val_loss: 0.2328\n","Epoch 24/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 0.3224 - val_loss: 0.2106\n","Epoch 25/50\n","2275/2275 [==============================] - 126s 55ms/step - loss: 0.3013 - val_loss: 0.1952\n","Epoch 26/50\n","2275/2275 [==============================] - 128s 56ms/step - loss: 0.2848 - val_loss: 0.1952\n","Epoch 27/50\n","2275/2275 [==============================] - 128s 56ms/step - loss: 0.2740 - val_loss: 0.1943\n","Epoch 28/50\n","2275/2275 [==============================] - 128s 56ms/step - loss: 0.2591 - val_loss: 0.1804\n","Epoch 29/50\n","2275/2275 [==============================] - 127s 56ms/step - loss: 0.2509 - val_loss: 0.1827\n","Epoch 30/50\n","2275/2275 [==============================] - 128s 56ms/step - loss: 0.2359 - val_loss: 0.1730\n","Epoch 31/50\n","2275/2275 [==============================] - 128s 56ms/step - loss: 0.2247 - val_loss: 0.1630\n","Epoch 32/50\n","2275/2275 [==============================] - 127s 56ms/step - loss: 0.2133 - val_loss: 0.1556\n","Epoch 33/50\n","2275/2275 [==============================] - 126s 55ms/step - loss: 0.2050 - val_loss: 0.1599\n","Epoch 34/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 0.1982 - val_loss: 0.1629\n","Epoch 35/50\n","2275/2275 [==============================] - 126s 55ms/step - loss: 0.1897 - val_loss: 0.1428\n","Epoch 36/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 0.1822 - val_loss: 0.1353\n","Epoch 37/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 0.1762 - val_loss: 0.1400\n","Epoch 38/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 0.1700 - val_loss: 0.1305\n","Epoch 39/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 0.1639 - val_loss: 0.1398\n","Epoch 40/50\n","2275/2275 [==============================] - 126s 55ms/step - loss: 0.1586 - val_loss: 0.1374\n","Epoch 41/50\n","2275/2275 [==============================] - 126s 55ms/step - loss: 0.1555 - val_loss: 0.1306\n","Epoch 42/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 0.1496 - val_loss: 0.1177\n","Epoch 43/50\n","2275/2275 [==============================] - 126s 55ms/step - loss: 0.1465 - val_loss: 0.1242\n","Epoch 44/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 0.1432 - val_loss: 0.1198\n","Epoch 45/50\n","2275/2275 [==============================] - 125s 55ms/step - loss: 0.1386 - val_loss: 0.1232\n","Epoch 46/50\n","2275/2275 [==============================] - 126s 55ms/step - loss: 0.1341 - val_loss: 0.1181\n","Epoch 47/50\n","2275/2275 [==============================] - 126s 56ms/step - loss: 0.1309 - val_loss: 0.1194\n","Epoch 48/50\n","2275/2275 [==============================] - 126s 55ms/step - loss: 0.1268 - val_loss: 0.1150\n","Epoch 49/50\n","2275/2275 [==============================] - 126s 55ms/step - loss: 0.1214 - val_loss: 0.1153\n","Epoch 50/50\n","2275/2275 [==============================] - 126s 55ms/step - loss: 0.1167 - val_loss: 0.1138\n"]}],"source":["history = model.fit(\n","    tf_train_dataset,\n","    validation_data=tf_eval_dataset,\n","    epochs = epochs)\n","    "],"id":"61487b7a"},{"cell_type":"code","execution_count":57,"metadata":{"id":"3681a235","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646931348092,"user_tz":-60,"elapsed":31,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}},"outputId":"bfce7a51-5365-4bed-c51c-3092b5b40a99"},"outputs":[{"output_type":"stream","name":"stdout","text":["| ID | GPU | MEM |\n","------------------\n","|  0 | 61% | 53% |\n"]}],"source":["GPUtil.showUtilization()"],"id":"3681a235"},{"cell_type":"markdown","metadata":{"id":"UMaHMrikFm-8"},"source":["# Saving the genre model\n"],"id":"UMaHMrikFm-8"},{"cell_type":"code","source":["#genre_names = [\"blues\", \"country\", \"jazz\", \"metal\", \"pop\", \"rock\"] \n","#genre_names[5]"],"metadata":{"id":"p0Gt9a7bJEXz","executionInfo":{"status":"ok","timestamp":1646931348093,"user_tz":-60,"elapsed":27,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"id":"p0Gt9a7bJEXz","execution_count":58,"outputs":[]},{"cell_type":"code","execution_count":59,"metadata":{"id":"H1vNhVk6Fq4P","executionInfo":{"status":"ok","timestamp":1646931348094,"user_tz":-60,"elapsed":25,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["# All the above cells are run 6 times with the same hyperparameters that are obtained \n","# using the pop_genre as context data (with most lines) to save time and have \n","# comparable results of syntax and semantics\n","\n","# from https://huggingface.co/docs/transformers/model_sharing\n","\n","#model_path = \"/content/drive/MyDrive/EchoCanyon/saved_model/blues\"\n","#model_path = \"/content/drive/MyDrive/EchoCanyon/saved_model/country\"\n","#model_path = \"/content/drive/MyDrive/EchoCanyon/saved_model/jazz\"\n","model_path = \"/content/drive/MyDrive/EchoCanyon/saved_model/metal\"\n","#model_path = \"/content/drive/MyDrive/EchoCanyon/saved_model/pop\" \n","#model_path = \"/content/drive/MyDrive/EchoCanyon/saved_model/rock\""],"id":"H1vNhVk6Fq4P"},{"cell_type":"code","execution_count":60,"metadata":{"id":"Ghw8qBB8dQtg","executionInfo":{"status":"ok","timestamp":1646931361036,"user_tz":-60,"elapsed":12965,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["#https://huggingface.co/docs/transformers/model_sharing\n","\n","model.save_pretrained(model_path)"],"id":"Ghw8qBB8dQtg"},{"cell_type":"code","source":["DONE"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":168},"id":"TLvwazfENYd4","executionInfo":{"status":"error","timestamp":1646931361466,"user_tz":-60,"elapsed":487,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}},"outputId":"1eb34c71-71cc-45d0-dd1a-32f50a785f16"},"id":"TLvwazfENYd4","execution_count":61,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-61-87f6c984fac4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mDONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'DONE' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"SAwtLIrR3qsp"},"source":["## Test"],"id":"SAwtLIrR3qsp"},{"cell_type":"code","execution_count":null,"metadata":{"id":"63770f80","executionInfo":{"status":"aborted","timestamp":1646931361444,"user_tz":-60,"elapsed":463,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["# FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","# CHANGES: None\n","\n","\"\"\"prompt = \"What did the chicken say afer crossing the road\"\n","n_generations = 5 # runs \n","\n","lyrics = prompt\n","\n","for i in range(n_generations):\n","    \n","    lyrics += generator(lyrics[-100:], return_full_text = False)[0][\"generated_text\"]\n","    \n","print(lyrics)\n","\n","#eos enf of sentence is used a  pad token\"\"\""],"id":"63770f80"},{"cell_type":"markdown","metadata":{"id":"rFCircC15Xy6"},"source":["# Hyperparameter Tuning"],"id":"rFCircC15Xy6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"836a7a89","executionInfo":{"status":"aborted","timestamp":1646931361445,"user_tz":-60,"elapsed":463,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["\"\"\"# FROM: 11 Hyperparameter Search Tensorboard\n","# CHANGES: None\n","\n","## Imports\n","\n","%load_ext tensorboard\n","\n","import os\n","# to use or not to use GPU\n","os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n","\n","import json\n","import random\n","import re\n","from collections import Counter\n","import tensorflow as tf\n","from tensorflow.keras import layers\n","from tensorboard.plugins.hparams import api as hp  # for hparam vis\n","from official.nlp import optimization \n","import shutil\n","import numpy as np\n","from tensorboard import notebook\n","from sklearn.utils import class_weight\n","from sklearn.metrics import precision_recall_fscore_support\n","\"\"\""],"id":"836a7a89"},{"cell_type":"code","execution_count":null,"metadata":{"id":"dc1ff988","executionInfo":{"status":"aborted","timestamp":1646931361446,"user_tz":-60,"elapsed":463,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["\"\"\"# FROM: 11 Hyperparameter Search Tensorboard\n","# CHANGES: Paths\n","\n","# path to the data\n","save_path = \"/content/drive/MyDrive/EchoCanyon/lyrics/\"\n","\n","\n","# setting up logging directory\n","log_dir = '/content/drive/MyDrive/EchoCanyon/log_dir/'\n","\n","try:\n","    shutil.rmtree(log_dir) # clearing logging directory <------------------\n","except:\n","    pass\n","    \n","if not os.path.exists(log_dir):\n","    os.makedirs(log_dir)\n","    \"\"\""],"id":"dc1ff988"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5YfJTtxrBkYW","executionInfo":{"status":"aborted","timestamp":1646931361446,"user_tz":-60,"elapsed":462,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["\"\"\"# FROM: 11 Hyperparameter Search Tensorboard\n","# CHANGES: None\n","\n","# loading your own lyrics file or the one available on moodle\n","with open(save_path + \"pop_lyrics.json\", \"r\", encoding = \"utf8\") as f:\n","    \n","    lyrics_dict = json.load(f)\n","    \n","# sampling, if there are more than 5 labels\n","n_artists = min(5, len(lyrics_dict.keys()))\n","random.seed(42)\n","artist_sample = random.sample(list(lyrics_dict.keys()), n_artists)\n","lyrics_dict = {artist:lyrics for artist, lyrics in lyrics_dict.items() if artist in artist_sample}\n","print([key for key in lyrics_dict.keys()])\n","\"\"\""],"id":"5YfJTtxrBkYW"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0aO_-mlEBkm8","executionInfo":{"status":"aborted","timestamp":1646931361448,"user_tz":-60,"elapsed":464,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["\"\"\"# FROM: 11 Hyperparameter Search Tensorboard\n","# CHANGES: None\n","\n","# extracting lines and artists\n","lines = []\n","artists = []\n","\n","for artist, lyrics in lyrics_dict.items():\n","    \n","    for title, lyric in lyrics.items():\n","        \n","        lyrics_lines = [re.sub(\"\\r\", \"\", line) for line in lyric.split(\"\\n\")]\n","        \n","        lyrics_lines = [line for line in lyrics_lines if re.search(\"\\w\", line) and line != \"None\"]\n","\n","        for line in set(lyrics_lines):\n","            lines.append(line)\n","            artists.append(artist)\n","\n","print(len(lines))\n","print(len(artists))\n","\"\"\""],"id":"0aO_-mlEBkm8"},{"cell_type":"code","execution_count":null,"metadata":{"id":"KxoyHAR-BlFg","executionInfo":{"status":"aborted","timestamp":1646931361449,"user_tz":-60,"elapsed":464,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["\"\"\"# FROM: 11 Hyperparameter Search Tensorboard\n","# CHANGES: None\n","\n","# extracting lines and artists\n","lines = []\n","artists = []\n","\n","for artist, lyrics in lyrics_dict.items():\n","    \n","    for title, lyric in lyrics.items():\n","        \n","        lyrics_lines = [re.sub(\"\\r\", \"\", line) for line in lyric.split(\"\\n\")]\n","        \n","        lyrics_lines = [line for line in lyrics_lines if re.search(\"\\w\", line) and line != \"None\"]\n","\n","        for line in set(lyrics_lines):\n","            lines.append(line)\n","            artists.append(artist)\n","\n","print(len(lines))\n","print(len(artists))\n","\"\"\""],"id":"KxoyHAR-BlFg"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ew7u7SL_BlUj","executionInfo":{"status":"aborted","timestamp":1646931361450,"user_tz":-60,"elapsed":465,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["\"\"\"# FROM: 11 Hyperparameter Search Tensorboard\n","# CHANGES: None\n","\n","# Selecting a smaller subset for faster training demonstration\n","n_lines = 27983\n","\n","sample = random.sample(range(0,len(lines)), n_lines)\n","lines = [line for i,line in enumerate(lines) if i in sample]\n","artists = [artist for i,artist in enumerate(artists) if i in sample]\n","Counter(artists)\n","\"\"\""],"id":"ew7u7SL_BlUj"},{"cell_type":"code","execution_count":null,"metadata":{"id":"fRK1IxB9BlgR","executionInfo":{"status":"aborted","timestamp":1646931361451,"user_tz":-60,"elapsed":465,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["\"\"\"# FROM: 11 Hyperparameter Search Tensorboard\n","# CHANGES: None\n","\n","# transforming to a tensorflow dataset\n","\n","# inputs\n","inputs = tf.data.Dataset.from_tensor_slices(lines) #.repeat() #https://stackoverflow.com/questions/49531286/cannot-batch-tensors-with-different-shapes-in-component-0-with-tf-data-dataset\n","\n","input_vectorizer = layers.TextVectorization(\n","    standardize=\"lower_and_strip_punctuation\",\n","    split = \"whitespace\",\n","    output_mode='int',\n","    max_tokens = 2000,\n","    output_sequence_length = 10)\n","\n","input_vectorizer.adapt(inputs)\n","inputs = inputs.map(input_vectorizer)\n","\n","# target dict\n","artist_dict = {artist: i for i, artist in enumerate(list(set(artists)))}\n","artist_dict_rev = {i: artist for artist, i in artist_dict.items()}\n","\n","# targets\n","artists_num = [artist_dict[artist] for artist in artists]\n","targets = tf.data.Dataset.from_tensor_slices(artists_num)\n","target_vectorizer = layers.CategoryEncoding(num_tokens = len(artist_dict), output_mode=\"one_hot\")\n","targets = targets.map(target_vectorizer)\n","\n","# class weights for unbalanced datasets\n","balanced_class_weights = dict(enumerate(class_weight.compute_class_weight('balanced',\n","                                                 classes = list(artist_dict_rev.keys()),\n","                                                 y = artists_num)))\n","# num of examples from 1 artist can make the model biased for that if it dominates otherwise\n","\n","# zipping\n","dataset = tf.data.Dataset.zip((inputs, targets))\n","\n","# shuffling\n","n_examples = tf.data.experimental.cardinality(dataset).numpy()\n","dataset = dataset.shuffle(n_examples, seed = 42, reshuffle_each_iteration=False)\n","\n","# !!!!! Important: setting the seed does not prevent different shuffling at each epoch, \n","# !!!!! set reshuffle_each_iteration=False if used\n","\n","# check dataset\n","for input_, target in dataset.take(3):\n","    print(input_)\n","    print(target)\n","    print(artist_dict_rev[tf.argmax(target).numpy()])\n","    print(\"\\n\")\n","\n","print(\"Class counts and weights:\")\n","print(Counter(artists_num))\n","print(balanced_class_weights)\n","\n","\"\"\""],"id":"fRK1IxB9BlgR"},{"cell_type":"code","execution_count":null,"metadata":{"id":"yA11wQbHBlv5","executionInfo":{"status":"aborted","timestamp":1646931361452,"user_tz":-60,"elapsed":465,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["\"\"\"# FROM: 11 Hyperparameter Search Tensorboard\n","# CHANGES: None\n","\n","# splitting and batching\n","\n","AUTOTUNE = tf.data.AUTOTUNE\n","batch_size = 32\n","val_size = 0.1\n","\n","# splitting, batching\n","val_size = round(val_size*n_examples)\n","test_dataset = dataset.take(val_size).batch(batch_size=batch_size, drop_remainder=True)\n","val_dataset = dataset.skip(val_size).take(val_size).batch(batch_size=batch_size, drop_remainder=True)\n","train_dataset = dataset.skip(val_size*2).batch(batch_size=batch_size, drop_remainder=True)\n","\n","# prefetching\n","test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n","val_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n","train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n","\n","print(len(train_dataset))\n","print(len(val_dataset))\n","print(len(test_dataset))\n","\"\"\""],"id":"yA11wQbHBlv5"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9YS3huS6Bl8S","executionInfo":{"status":"aborted","timestamp":1646931361453,"user_tz":-60,"elapsed":465,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["\"\"\"# FROM: 11 Hyperparameter Search Tensorboard\n","# CHANGES: None\n","\n","# defining our hyperparameter search space -> 2 methods: RealInterval, Discrete\n","hp_learning_rate = hp.HParam('learning_rate', hp.Discrete([0.1, 0.01, 0.001, 0.0001, 0.00001])) \n","# currently possible with only two values for grid search\n","hp_optimizer = hp.HParam('optimizer', hp.Discrete(['adamw', 'sgd']))\n","hp_class_weights = hp.HParam('class_weights', hp.Discrete(['none', 'balanced']))\n","#hp_hidden_units = hp.HParam('hidden_units', hp.Discrete([8,32]))  # OR hp.Discrete([8, 32])\n","\n","# fixed parameters and dimensions\n","params = {\"vocab_size\":input_vectorizer.vocabulary_size() +1,  # +1: Padding\n","            \"embedding_dim\": 256,\n","            \"hidden_units\": 128,\n","            \"n_labels\": len(artist_dict),\n","            \"n_epochs\": 10,\n","            \"n_steps\": 3*len(train_dataset)}\n","\n","\n","# initializing the logger\n","with tf.summary.create_file_writer(log_dir).as_default():\n","    hp.hparams_config(\n","    hparams=[hp_learning_rate, hp_optimizer, hp_class_weights],#, hp_hidden_units],\n","    metrics=[hp.Metric(\"accuracy\", display_name='Accuracy'),\n","            hp.Metric(\"precision\", display_name= \"Precision\"),\n","            hp.Metric(\"recall\", display_name = \"Recall\"),\n","            hp.Metric(\"f1\", display_name = \"F1\")],\n","    )  # see notes for more info aout metrics\n","\n","\"\"\"\n"],"id":"9YS3huS6Bl8S"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ymgOvMrUBmII","executionInfo":{"status":"aborted","timestamp":1646931361454,"user_tz":-60,"elapsed":466,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["\"\"\"# FROM: 11 Hyperparameter Search Tensorboard\n","# CHANGES: None\n","\n","# functions to run a trial with specified hyperparameters and fixed parameters\n","\n","def hp_search_trial(log_dir, params, hparams):\n","    model = tf.keras.Sequential([\n","    layers.Embedding(params[\"vocab_size\"], params[\"embedding_dim\"], mask_zero = True), # masks zero paddings but not any other value\n","    #layers.Masking(mask_value = 0), -> NOT needed\n","    layers.GlobalAveragePooling1D(),\n","    layers.Dense(params[\"hidden_units\"], activation = tf.nn.leaky_relu),\n","    # using Leaky ReLU: similar to ReLU with a little tweak for negative input values\n","    layers.Dense(params[\"n_labels\"], activation = tf.nn.softmax)])\n","\n","    if hparams[hp_optimizer] == \"sgd\":\n","        \n","        optimizer = tf.keras.optimizers.SGD(learning_rate=hparams[hp_learning_rate])\n","        \n","    elif hparams[hp_optimizer] == \"adamw\":  # updated version of adam\n","        \n","        optimizer = optimization.create_optimizer(init_lr=hparams[hp_learning_rate],\n","                                            num_train_steps=params[\"n_steps\"],\n","                                            num_warmup_steps=round(0.1* params[\"n_steps\"]),\n","                                            optimizer_type='adamw')\n","\n","    class_weights = balanced_class_weights if hparams[hp_class_weights] == \"balanced\" else None\n","\n","    model.compile(\n","        optimizer=optimizer,\n","        loss=tf.keras.losses.CategoricalCrossentropy(),\n","        metrics=['accuracy']\n","    )\n","\n","    model.fit(train_dataset,validation_data=val_dataset, epochs=params[\"n_epochs\"],\n","            callbacks=[tf.keras.callbacks.TensorBoard(log_dir=log_dir, \n","                                                        histogram_freq=1, \n","                                                        update_freq='batch')],\n","            class_weight = class_weights) \n","    \n","    test_loss, test_accuracy = model.evaluate(test_dataset)\n","    \n","    true_labels = np.concatenate([y for x, y in test_dataset], axis=0).argmax(axis = -1)\n","    preds = model.predict(test_dataset).argmax(axis = -1)\n","    precision, recall, f1, support = precision_recall_fscore_support(true_labels, preds, average = \"macro\")\n","    # without avg. it will give out each class individually\n","    #precision, recall, f1, support = precision_recall_fscore_support(true_labels, preds)\n","    \n","    return test_accuracy, precision, recall, f1\n","\n","\n","def run(log_dir, params, hparams):\n","    \n","    with tf.summary.create_file_writer(log_dir).as_default():\n","        hp.hparams(hparams)  # record the values used in this trial\n","        \n","        test_accuracy, precision, recall, f1 = hp_search_trial(log_dir, params, hparams)\n","        tf.summary.scalar(\"accuracy\", test_accuracy, step=1)\n","        # you can also log batch accuracy to see a trend, and train longer if needed\n","        tf.summary.scalar(\"precision\", precision, step = 1)\n","        tf.summary.scalar(\"recall\", recall, step = 1)\n","        tf.summary.scalar(\"f1\", f1, step = 1)\n","\n","        \"\"\""],"id":"ymgOvMrUBmII"},{"cell_type":"markdown","metadata":{"id":"IYq6tvsAFbWI"},"source":["## Running Grid Search"],"id":"IYq6tvsAFbWI"},{"cell_type":"code","execution_count":null,"metadata":{"id":"zi_PseJgBmUW","executionInfo":{"status":"aborted","timestamp":1646931361454,"user_tz":-60,"elapsed":465,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["\"\"\"# FROM: 11 Hyperparameter Search Tensorboard\n","# CHANGES: None\n","\n","session_num = 0\n","\n","for optimizer in hp_optimizer.domain.values:\n","    for learning_rate in hp_learning_rate.domain.values:#(hp_learning_rate.domain.min_value, hp_learning_rate.domain.max_value):\n","        for class_weights in hp_class_weights.domain.values:\n","            #for hidden_units in hp_class_weights.domain.values:  # (hp_hidden_units.domain.min_value, hp_hidden_units.domain.max_value):\n","                hparams = {\n","                  hp_optimizer: optimizer,\n","                  hp_learning_rate: learning_rate,\n","                  hp_class_weights: class_weights\n","                  }\n","                run_name = f\"run{session_num}_{optimizer}_lr{learning_rate}_weights={class_weights}\"\n","                print(f'--- Starting trial: {run_name}')\n","                print({h.name: hparams[h] for h in hparams})\n","                run(f'{log_dir}{run_name}', params, hparams)\n","                session_num += 1\n","\"\"\""],"id":"zi_PseJgBmUW"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZhUx4HruBmgy","executionInfo":{"status":"aborted","timestamp":1646931361455,"user_tz":-60,"elapsed":466,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["\"\"\"# FROM: 11 Hyperparameter Search Tensorboard\n","# CHANGES: None\n","\n","!tensorboard --logdir logs/hparam_tuning --port 9000\n","\"\"\""],"id":"ZhUx4HruBmgy"},{"cell_type":"code","execution_count":null,"metadata":{"id":"xBuP444JBndw","executionInfo":{"status":"aborted","timestamp":1646931361455,"user_tz":-60,"elapsed":465,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["\"\"\"# FROM: 11 Hyperparameter Search Tensorboard\n","# CHANGES: None\n","\n","# if it is not working, try another port\n","\n","# listing tensorboard instances\n","notebook.list()\n","\n","# resetting tensorboard\n","\n","# Linux\n","#!kill #ProcessID\n","\n","# Windows\n","#!taskkill /f /pid #ProcessID\n","# you also have to delete .tensorflow.info in your %TEMP% directory\n","\"\"\""],"id":"xBuP444JBndw"},{"cell_type":"markdown","source":["# Training all at once\n"],"metadata":{"id":"dSRKSeXdGxkk"},"id":"dSRKSeXdGxkk"},{"cell_type":"code","source":["for genre_index in range(1,6): \n","    #with open(\"/content/drive/MyDrive/EchoCanyon/lyrics/blues_lyrics.json\", \"r\", encoding = \"utf8\") as f:\n","    #with open(\"/content/drive/MyDrive/EchoCanyon/lyrics/country_lyrics.json\", \"r\", encoding = \"utf8\") as f:\n","    #with open(\"/content/drive/MyDrive/EchoCanyon/lyrics/jazz_lyrics.json\", \"r\", encoding = \"utf8\") as f:\n","    #with open(\"/content/drive/MyDrive/EchoCanyon/lyrics/metal_lyrics.json\", \"r\", encoding = \"utf8\") as f:\n","    #with open(\"/content/drive/MyDrive/EchoCanyon/lyrics/pop_lyrics.json\", \"r\", encoding = \"utf8\") as f:\n","    #with open(\"/content/drive/MyDrive/EchoCanyon/lyrics/rock_lyrics.json\", \"r\", encoding = \"utf8\") as f:\n","    \n","    lyrics_path = \"/content/drive/MyDrive/EchoCanyon/lyrics/\"\n","    genre_names = [\"blues\", \"country\", \"jazz\", \"metal\", \"pop\", \"rock\"] \n","    lyrics_path += (genre_names[genre_index] + \"_lyrics.json\")\n","    print(\"#############\", genre_index, genre_names[genre_index], \"#############\")\n","    with open(lyrics_path, \"r\", encoding = \"utf8\") as f:\n","\n","        lyrics_dict = {}\n","        lyrics_dict = json.load(f)\n","\n","    # FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","    # CHANGES: None\n","\n","\n","\n","    # reformatting lyrics\n","\n","    lyrics = {\"text\":[], \"artist\":[]}\n","    for artist, titles in lyrics_dict.items():\n","        \n","        for title, text in titles.items():\n","            \n","            lyrics[\"artist\"].append(artist)\n","            lyrics[\"text\"].append(text)\n","\n","    # FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","    # CHANGES: None\n","\n","\n","\n","    # AutoTokenizer will find and load the right tokenizer for all common models in the huggingface library\n","    tokenizer = AutoTokenizer.from_pretrained(model_name)\n","\n","    i = random.randint(0, len(lyrics[\"text\"]))\n","    example_text = lyrics[\"text\"][i][0:200]\n","    example_text_tokenized = tokenizer(example_text)\n","    print([tokenizer.decode(token) for token in example_text_tokenized[\"input_ids\"]])\n","\n","\n","\n","    # FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","    # CHANGES: None\n","\n","    # transforming lyrics into dataset format\n","\n","    dataset = Dataset.from_dict(lyrics)\n","    print(dataset)\n","\n","\n","\n","    # FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","    # CHANGES: None\n","\n","    # tokenizing before chunking, to ensure equal lengths\n","\n","    def pretokenization(text, tokenizer):\n","        tokens = tokenizer(text, truncation = False, add_special_tokens = False, return_attention_mask = False)\n","        return {\"tokens\":[tokenizer.decode(token) for token in tokens[\"input_ids\"]]}\n","\n","    tokenized_dataset = dataset.map(lambda x: pretokenization(x[\"text\"],tokenizer), remove_columns = [\"text\"])\n","    print(tokenized_dataset)\n","    i = random.randint(0, len(dataset[\"text\"]))\n","    print(tokenized_dataset[\"tokens\"][i][0:20])\n","\n","\n","\n","    # FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","    # CHANGES: None\n","\n","    # chunking the lyrics into parts of equal length\n","    # greater chunks allow longer-range dependencies but also increase computation \n","    chunk_size = 25  # increases computation quadraticly, basically\n","    # depens on how many close words to consider during training over the current word \n","    #\n","\n","    def chunking(examples, chunk_size):\n","        chunks = []\n","        artists = []\n","        for tokens, artist in zip(examples[\"tokens\"], examples[\"artist\"]):\n","\n","            for i in range(0, len(tokens)-chunk_size, chunk_size):\n","                \n","                chunks.append(tokens[i:i+chunk_size])\n","                artists.append(artist)\n","        \n","        return {'tokens': chunks, \"artist\": artists}\n","\n","    chunked_dataset = tokenized_dataset.map(lambda x: chunking(x, chunk_size), batched = True, \n","                                            remove_columns = tokenized_dataset.column_names)\n","\n","    # check if all chunks are of equal length\n","    print(max(len(ids) for ids in chunked_dataset[\"tokens\"]))\n","    print(min(len(ids) for ids in chunked_dataset[\"tokens\"]))\n","\n","    print(chunked_dataset)\n","\n","\n","\n","    # FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","    # CHANGES: None\n","\n","    # stratifying by artist\n","\n","    n = Counter(chunked_dataset[\"artist\"]).most_common()[-1][1]  # from library->Collections\n","\n","    def stratifying(examples, n):  # to have same amount of lines from both artists\n","        \n","        chunks = []\n","        artists = []\n","        \n","        for artist in set(examples[\"artist\"]):\n","            \n","            artist_chunks = [chunk for a, chunk in zip(examples[\"artist\"], examples[\"tokens\"]) if a == artist]\n","            artist_chunks = random.sample(artist_chunks, n)\n","            \n","            for chunk in artist_chunks:\n","                \n","                chunks.append(chunk)\n","                artists.append(artist)\n","            \n","            \n","        return {'tokens': chunks, \"artist\": artists}\n","        \n","    stratified_dataset = chunked_dataset.map(lambda x: stratifying(x, n), batched = True, batch_size = None,\n","                                            remove_columns = tokenized_dataset.column_names)\n","\n","    print(stratified_dataset)\n","    print(Counter(stratified_dataset[\"artist\"]).most_common())\n","\n","\n","\n","    # FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","    # CHANGES: None\n","\n","    # running tokenization again, to retrieve input_ids, labels and the attention_masks\n","\n","    def tokenization(tokens):\n","        tokenized = tokenizer(tokens)\n","        return  {\"input_ids\": tf.squeeze(tokenized[\"input_ids\"]),\n","                # duplicating the inputs for our labels\n","                # \"the model of the ðŸ¤— Transformers library apply the shifting to the right, so we don't need to do it manually\"\n","                \"labels\": tf.squeeze(tokenized[\"input_ids\"]), \n","                \"attention_mask\": tf.squeeze(tokenized[\"attention_mask\"])}\n","\n","    final_dataset = stratified_dataset.map(lambda x:tokenization(x[\"tokens\"]))\n","    print(final_dataset)\n","\n","\n","\n","    # FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","    # CHANGES: None\n","\n","    # shuffling, batching, splitting  # needed when using tf and it needs to be transfored to a Tensorflow Dataset\n","    from transformers import DefaultDataCollator\n","\n","    batch_size = 2\n","    n_batches = round(final_dataset.num_rows/batch_size)\n","    n_eval_batches = round(0.1*n_batches)\n","    n_train_batches = n_batches - n_eval_batches\n","\n","\n","    # transforming to a tensorflow dataset\n","    data_collator = DefaultDataCollator(return_tensors= \"tf\")\n","\n","    tf_dataset = final_dataset.to_tf_dataset(columns=[\"attention_mask\", \"input_ids\", \"labels\"],\n","                                                                        shuffle = True, \n","                                                                        batch_size = batch_size,\n","                                                                        collate_fn = data_collator)\n","\n","    # !!!!! Important: setting the seed does not prevent different shuffling at each epoch, \n","    # !!!!! set reshuffle_each_iteration=False if used\n","\n","\n","    tf_train_dataset = tf_dataset.take(n_train_batches)\n","    tf_eval_dataset = tf_dataset.skip(n_train_batches).take(n_eval_batches)\n","\n","    print(tf_train_dataset)\n","\n","\n","\n","    # FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","    # CHANGES: None\n","\n","    # inspecting the configuration of the pretrained model\n","    config = AutoConfig.from_pretrained(model_name)\n","\n","    # for more elaboration of all the configuration details check here:\n","    # https://huggingface.co/docs/transformers/model_doc/gpt2#transformers.GPT2Config\n","    # print(config)\n","\n","    # \"n_ctx\": 1024, sequence dim\n","    # \"n_embd\": 768, embedding dim\n","    # \"n_head\": 12, num of attetion heads\n","\n","\n","\n","    # FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","    # CHANGES: None\n","\n","    # loading the model including its causal language modeling head\n","\n","    model = TFAutoModelForCausalLM.from_pretrained(model_name)\n","\n","\n","\n","    # FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","    # CHANGES: Hyperparameter Tuning see next section\n","\n","    # initializing the optimizer and defining our learning rate schedule\n","\n","    epochs = 50\n","    num_train_steps = epochs * n_train_batches\n","    warmup_ratio = 0.1\n","    num_warmup_steps = int(warmup_ratio*num_train_steps)\n","\n","    init_lr = 1e-3\n","\n","    optimizer = optimization.create_optimizer(init_lr=init_lr,\n","                                              num_train_steps=num_train_steps,\n","                                              num_warmup_steps=num_warmup_steps,\n","                                              optimizer_type='adamw')\n","\n","    # compiling the model\n","    model.compile(optimizer=optimizer)\n","\n","\n","\n","    history = model.fit(\n","        tf_train_dataset,\n","        validation_data=tf_eval_dataset,\n","        epochs = epochs)\n","        \n","\n","\n","    # All the above cells are run 6 times with the same hyperparameters that are obtained \n","    # using the pop_genre as context data (with most lines) to save time and have \n","    # comparable results of syntax and semantics\n","\n","    # from https://huggingface.co/docs/transformers/model_sharing\n","\n","    model_path = \"/content/drive/MyDrive/EchoCanyon/saved_model/\"\n","    genre_names = [\"blues\", \"country\", \"jazz\", \"metal\", \"pop\", \"rock\"]\n","    #print(\"#############\", genre_index, genre_names[genre_index], \"#############\")\n","    model_path += genre_names[genre_index]\n","\n","    #model_path = \"/content/drive/MyDrive/EchoCanyon/saved_model/blues\"\n","    #model_path = \"/content/drive/MyDrive/EchoCanyon/saved_model/country\"\n","    #model_path = \"/content/drive/MyDrive/EchoCanyon/saved_model/jazz\"\n","    #model_path = \"/content/drive/MyDrive/EchoCanyon/saved_model/metal\"\n","    #model_path = \"/content/drive/MyDrive/EchoCanyon/saved_model/pop\" \n","    #model_path = \"/content/drive/MyDrive/EchoCanyon/saved_model/rock\"\n","\n","    model.save_pretrained(model_path)"],"metadata":{"id":"OFjskcXEG1pJ","executionInfo":{"status":"aborted","timestamp":1646931361456,"user_tz":-60,"elapsed":466,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"id":"OFjskcXEG1pJ","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ktf33C7uhpBh"},"source":["# Genre Specific Generators for Usage\n"],"id":"ktf33C7uhpBh"},{"cell_type":"code","execution_count":null,"metadata":{"id":"1Ibc1dXhGmHy","executionInfo":{"status":"aborted","timestamp":1646931361457,"user_tz":-60,"elapsed":467,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["# Choose Genre\n","genre = 4\n","model_path = \"/content/drive/MyDrive/EchoCanyon/saved_model/\"\n","genre_names = [\"blues\", \"country\", \"jazz\", \"metal\", \"pop\", \"rock\"]  # count from 0\n","model_path += genre_names[genre]\n","model_path"],"id":"1Ibc1dXhGmHy"},{"cell_type":"code","execution_count":null,"metadata":{"id":"OO8zK7ibuF5G","executionInfo":{"status":"aborted","timestamp":1646931361458,"user_tz":-60,"elapsed":467,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["model = TFAutoModelForCausalLM.from_pretrained(model_path)\n","\n"],"id":"OO8zK7ibuF5G"},{"cell_type":"code","execution_count":null,"metadata":{"id":"M4cyo8wZhxZg","executionInfo":{"status":"aborted","timestamp":1646931361458,"user_tz":-60,"elapsed":468,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["# FROM: 10 Finetuning a Language Model with Huggingface - Lyrics Mashup\n","# CHANGES: Redefining tokenizer and generator to match the genre model\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","generator = pipeline('text-generation',model=model, tokenizer=tokenizer) \n","\n","#prompt = \"Peace sells, but who is buying\"  \n","prompt = \"Como esta\" \n","\n","# Too random with 1-2 words, doesnt get the context\n","# Performs better with one sentence\n","# Too restrictive and causes repetititions with a paragraph\n","\n","n_generations = 5 # runs \n","\n","lyrics = prompt\n","\n","for i in range(n_generations):\n","    \n","    lyrics += generator(lyrics[-100:], return_full_text = False)[0][\"generated_text\"]\n","    \n","print(lyrics)\n","\n","#eos enf of sentence is used a  pad token\n"],"id":"M4cyo8wZhxZg"},{"cell_type":"code","execution_count":null,"metadata":{"id":"hjjAdHaw122n","executionInfo":{"status":"aborted","timestamp":1646931361459,"user_tz":-60,"elapsed":468,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"outputs":[],"source":["lines = lyrics.split(\"\\n\")\n","#words = [\"\" for i in range(len(lines))]\n","#for count, line in enumerate(lines):\n","#    words[count] = line.split(\" \")"],"id":"hjjAdHaw122n"},{"cell_type":"code","source":["lines = lines[:-1]"],"metadata":{"id":"PJp3LjTp-Ztn","executionInfo":{"status":"aborted","timestamp":1646931361460,"user_tz":-60,"elapsed":469,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"id":"PJp3LjTp-Ztn","execution_count":null,"outputs":[]},{"cell_type":"code","source":["lyrics = '\\n'.join(lines)"],"metadata":{"id":"EH1eHvV5_24h","executionInfo":{"status":"aborted","timestamp":1646931361460,"user_tz":-60,"elapsed":468,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"id":"EH1eHvV5_24h","execution_count":null,"outputs":[]},{"cell_type":"code","source":["lyrics"],"metadata":{"id":"oHy2dg5gA0bl","executionInfo":{"status":"aborted","timestamp":1646931361461,"user_tz":-60,"elapsed":469,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"id":"oHy2dg5gA0bl","execution_count":null,"outputs":[]},{"cell_type":"code","source":["from os.path import exists\n","import shutil\n","\n","i = 0\n","path = '/content/drive/MyDrive/EchoCanyon/gen_lyrics/lyrics_current.txt'\n","\n","while exists(path):\n","    i += 1\n","    path = '/content/drive/MyDrive/EchoCanyon/gen_lyrics/lyrics_' + str(i) + '.txt'  \n","    if not exists(path):\n","        original = '/content/drive/MyDrive/EchoCanyon/gen_lyrics/lyrics_current.txt'\n","        target = path\n","        shutil.copyfile(original, target)\n","        break\n","\n","with open('/content/drive/MyDrive/EchoCanyon/gen_lyrics/lyrics_current.txt', 'w') as f:\n","    f.write(lyrics)   "],"metadata":{"id":"cx3rTY_lquwY","executionInfo":{"status":"aborted","timestamp":1646931361462,"user_tz":-60,"elapsed":470,"user":{"displayName":"Volkan Tatlikazan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjmHAs2j8h9Y8NaxNe2GgIdffGW5139mkQzJrykJQ=s64","userId":"02369655295950434275"}}},"id":"cx3rTY_lquwY","execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":["SAwtLIrR3qsp","rFCircC15Xy6"],"machine_shape":"hm","name":"generate_genre.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f89013d7ea76426f9082eb56b448a109":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_26863a415ad54d348db61a3156bda070","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fb63372d3d43472dace6bbf625a69620","IPY_MODEL_d8a51ddadcb84bd98e1f4f4b1d8e92b9","IPY_MODEL_7e312471bad64ecc8f8164d7b2ed455f"]}},"26863a415ad54d348db61a3156bda070":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fb63372d3d43472dace6bbf625a69620":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_7746bc0d825e45608dbea1cb69c8bb53","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_778b8e3f32534c3f804af7be9923c78c"}},"d8a51ddadcb84bd98e1f4f4b1d8e92b9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0f32cadc2fac47d9b2ab72592c726afa","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_88283314cd3f47e997defe1b4e8f2da8"}},"7e312471bad64ecc8f8164d7b2ed455f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_64aa5a41b1074e399d1c9e533b9b01c2","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 725/? [00:01&lt;00:00, 371.24ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_fe346866658e4823aa271a47b82ae19f"}},"7746bc0d825e45608dbea1cb69c8bb53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"778b8e3f32534c3f804af7be9923c78c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0f32cadc2fac47d9b2ab72592c726afa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"88283314cd3f47e997defe1b4e8f2da8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"64aa5a41b1074e399d1c9e533b9b01c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"fe346866658e4823aa271a47b82ae19f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9b529b573071433bac9d2a6382555eef":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_221ddad183584a37a0cb6f2ba660f32f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fffc839e3a494667b86cb003ea29d3d4","IPY_MODEL_ef25eeccd69942d880da58f5eb7f61f4","IPY_MODEL_2ea301bf4d1042b8a8a9a7835ae38e48"]}},"221ddad183584a37a0cb6f2ba660f32f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fffc839e3a494667b86cb003ea29d3d4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_bb240db5ee654bbcb4d0cd411384085b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_85e5d9f99cb94ec382a8cacdd959b95d"}},"ef25eeccd69942d880da58f5eb7f61f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2ab6c024ca814d4b90cb61c29742bb21","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_1f8951d1840e47e6b01f275286e01356"}},"2ea301bf4d1042b8a8a9a7835ae38e48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9fde0dce55b14d94850898cf6a1954a9","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00,  4.12ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2aa9e26798704940b789c3975ec432f9"}},"bb240db5ee654bbcb4d0cd411384085b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"85e5d9f99cb94ec382a8cacdd959b95d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2ab6c024ca814d4b90cb61c29742bb21":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"1f8951d1840e47e6b01f275286e01356":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9fde0dce55b14d94850898cf6a1954a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"2aa9e26798704940b789c3975ec432f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3209cbcf94a643e0a82d00cfcaaa1817":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_3d5c99c164504ed4beb8428653197eb4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_f1a4c4c086c8410fb319107452e3dac5","IPY_MODEL_4715902f29494193935c4d838feac8f4","IPY_MODEL_02bea20926b3445cb988ed2c6b8063b6"]}},"3d5c99c164504ed4beb8428653197eb4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f1a4c4c086c8410fb319107452e3dac5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0662bf0dc1d94092b231412ee8bb05af","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c9aced323b8c4a09b5da0e7c99fae967"}},"4715902f29494193935c4d838feac8f4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_e6c053e1a1d143118731999306f7bce3","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_09506516eedd4d5e9d5f5c5588a8b7c1"}},"02bea20926b3445cb988ed2c6b8063b6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_31b93b65cd9a45718a6441c4f0b07d46","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 1/1 [00:00&lt;00:00,  4.01ba/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4d286f58c0d9451da57b5d8f0b879d2f"}},"0662bf0dc1d94092b231412ee8bb05af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c9aced323b8c4a09b5da0e7c99fae967":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"e6c053e1a1d143118731999306f7bce3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"09506516eedd4d5e9d5f5c5588a8b7c1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"31b93b65cd9a45718a6441c4f0b07d46":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4d286f58c0d9451da57b5d8f0b879d2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b362d745ab83403b9e51ebdca3a36fcb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_9ee49089b35f4513965a422cc799c7fb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_65052c2bfea0441eb8b255a3a5daa720","IPY_MODEL_73ac942d8f624b7888dfe5013e2606ce","IPY_MODEL_d3615fcb16eb42b5ad3133c419428c44"]}},"9ee49089b35f4513965a422cc799c7fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"65052c2bfea0441eb8b255a3a5daa720":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b7359751809e467e90a44e42b61b62e1","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b0ac0d219ff245c887a7b43ab6d64734"}},"73ac942d8f624b7888dfe5013e2606ce":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_35df29c9c08147f5858f9f3f2014a5ca","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":1,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":1,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_14a948cd79514f2c90f4ab029893502d"}},"d3615fcb16eb42b5ad3133c419428c44":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_8fee981946e64056bcae6e5b8d33e367","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 5055/? [00:06&lt;00:00, 810.46ex/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_57278ee7e13f4bb29ff8a7c80a1835f3"}},"b7359751809e467e90a44e42b61b62e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b0ac0d219ff245c887a7b43ab6d64734":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"35df29c9c08147f5858f9f3f2014a5ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"14a948cd79514f2c90f4ab029893502d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":"20px","min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8fee981946e64056bcae6e5b8d33e367":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"57278ee7e13f4bb29ff8a7c80a1835f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}